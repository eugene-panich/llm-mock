PROJECT_NAME= llm-mock
SERVER_PORT=8001
LLM_URL_ENDPOINT=chatgpt/chat/completions
## MOCK_LLM_RESPONSE_TYPE can be 'lorem' or 'stored'
MOCK_LLM_RESPONSE_TYPE=lorem
MAX_LOREM_PARAS=8
# SET DEBUG TO * START DETAILED DEBUGGING LOGS AND OFF TO STOP
DEBUG=OFF
LLM_NAME=chatgpt
VALIDATE_REQUESTS=ON
# SET LOG_REQUESTS TO ON TO LOG DETAILS OF ALL INCOMING REQUESTS (VALIDATE REQUESTS MUST ALSO BE ON)
LOG_REQUESTS=ON
# RESPONSE DELAY SETTINGS (IN MILLISECONDS) - SET TO 0 TO DISABLE DELAY
RESPONSE_DELAY_MIN=3000
RESPONSE_DELAY_MAX=5000
